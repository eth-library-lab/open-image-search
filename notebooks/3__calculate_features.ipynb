{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Features\n",
    "\n",
    "this notebook uses a CNN to extract features from the images in the directory. \n",
    "The results are saved to a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_metadata_file(csv_fname_in, csv_fname_out = 'graphik_portal_{}.csv'):\n",
    "\n",
    "    # load picture metadata\n",
    "    src_fldr = os.path.join('..', 'data','raw','scraped')\n",
    "    output_fldr = os.path.join('..', 'data','interim')\n",
    "    csv_fpath = os.path.join(src_fldr, csv_fname_in)\n",
    "\n",
    "    col_names = ['title','img_url','detail_url','detail_description','object_id', 'request_num']\n",
    "    df = pd.read_csv(csv_fpath, index_col=0, header=None, na_values=['NaN'])\n",
    "    df.columns = col_names\n",
    "\n",
    "    #drop NA's\n",
    "    orig_len = df.shape[0]\n",
    "    df = df.dropna()\n",
    "    num_dropped = orig_len - df.shape[0]\n",
    "    print('dropped {:,} records due to NaN'.format(num_dropped))\n",
    "\n",
    "    # remove one row where a header was inaccorectly inserted\n",
    "    df = df.loc[df['object_id']!='object_id']\n",
    "\n",
    "    # change object id to int and set as index\n",
    "    df['object_id'] = df['object_id'].astype(np.int32)\n",
    "    df = df.set_index('object_id')\n",
    "    df = df.sort_index()\n",
    "\n",
    "    # drop rows that do not have images in the processed folder\n",
    "    img_fldr_path = os.path.join('..', 'data','processed','images')\n",
    "    img_fpath_lst = utils.get_list_of_files_in_dir(img_fldr_path, file_types = ['jpg', 'jpeg','png'], keep_fldr_path=False)\n",
    "    img_fpath_ser = pd.Series(img_fpath_lst, name='img_path')\n",
    "\n",
    "    # remove any duplicate files\n",
    "    img_fpath_ser = img_fpath_ser.drop_duplicates()\n",
    "\n",
    "    # set index as object id number\n",
    "    img_object_id = []\n",
    "\n",
    "    for f  in img_fpath_ser:\n",
    "\n",
    "        f_id = os.path.basename(f).split('.')[0]\n",
    "        try:\n",
    "            f_id = int(f_id)\n",
    "            img_object_id.append(f_id)\n",
    "        except:\n",
    "            print(f_id)\n",
    "\n",
    "    img_object_id = np.asarray(img_object_id, dtype=np.int64, order='C')\n",
    "    img_fpath_ser.index = img_object_id\n",
    "\n",
    "    # join series with image paths to df\n",
    "    df = df.join(img_fpath_ser, how='left', sort=False)\n",
    "    df = df.dropna(subset=['img_path',])\n",
    "\n",
    "    # write interim result to file\n",
    "    time_stamp = dt.now().strftime('%Y%m%d%H%M')\n",
    "    csv_fname_out = 'graphik_portal_{}.csv'.format(time_stamp)\n",
    "\n",
    "    output_fldr = os.path.join('..', 'data','interim')\n",
    "    csv_fpath = os.path.join(output_fldr, csv_fname_out)\n",
    "\n",
    "    df.to_csv(csv_fpath)\n",
    "    print(\"wrote out csv {} with {:,} records\".format(csv_fpath, df.shape[0]))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prep metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 5 records due to NaN\n",
      "found 9994 existing images\n",
      "wrote out csv ../data/interim/graphik_portal_202010081333.csv with 9,994 records\n"
     ]
    }
   ],
   "source": [
    "csv_fname_in = 'graphik_portal_results.csv'\n",
    "\n",
    "df = prep_metadata_file(csv_fname_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create tensorflow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
