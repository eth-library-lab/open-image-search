{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "parallel-treatment",
   "metadata": {},
   "source": [
    "# clean an input xl or csv\n",
    "- remove duplicates\n",
    "- remove NaN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "appreciated-connection",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('../src')\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "prescribed-booth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "legislative-parker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.819326108228923"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.random()*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "offensive-carol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 7)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sapphire-stockholm",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7973157608195564"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.uniform(.75,1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "collectible-croatia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.739803681787796"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sleep_time = random.randint(*sleep_time_range) + (random.random()*4)\n",
    "sleep_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "taken-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_output_fpath_string(dataset_name, fname, data_stage = 'interim', ftype_output='csv'):\n",
    "    \n",
    "    data_dir_output = os.path.join('..','data', data_stage, dataset_name)\n",
    "\n",
    "    fname_input = fname.split('.')[0]\n",
    "    fname_output = f'{fname_input}.{ftype_output}'\n",
    "    fpath_output = os.path.join(data_dir_output, fname_output)\n",
    "\n",
    "    return fpath_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "tracked-calvin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(fname, dataset_name, input_data_stage='raw'):\n",
    "    \n",
    "    data_dir_input = os.path.join('..','data', input_data_stage, dataset_name)\n",
    "    fpath_input = os.path.join(data_dir_input, fname)\n",
    "    ftype_input = fname.split('.')[-1]\n",
    "\n",
    "    if ftype_input == 'csv':\n",
    "        df = pd.read_csv(fpath_input)\n",
    "\n",
    "    elif ftype_input == 'xlsx':\n",
    "        df = pd.read_excel(fpath_input)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "digital-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(fname, dataset_name, ftype_output='csv', output_data_stage='interim'):\n",
    "    \"\"\"\n",
    "    clean NaN's and duplicates from input file and save to interim folder\n",
    "    \"\"\"\n",
    "\n",
    "    df = load_df(fname, dataset_name)\n",
    "    df = utils.drop_nans_and_duplicates(df)\n",
    "    \n",
    "    fpath_output = make_output_fpath_string(dataset_name, \n",
    "                                            fname, \n",
    "                                            data_stage=output_data_stage, \n",
    "                                            ftype_output=ftype_output)\n",
    "    utils.prep_dir(fpath_output)\n",
    "    df.to_csv(fpath_output)\n",
    "\n",
    "    output_rows = df.shape[0]\n",
    "    print(f\"wrote {ftype_output} with {output_rows} rows to {fpath_output}\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-vegetarian",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "polished-stack",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "brazilian-report",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 2892 due NaN's or duplicates\n",
      "wrote csv with 21107 rows to ../data/interim/ETHZ/image_search_ids.csv\n"
     ]
    }
   ],
   "source": [
    "    dataset_name = 'ETHZ'\n",
    "    fname = 'image_search_ids.xlsx'\n",
    "    ftype_output='csv'\n",
    "    output_data_stage='interim'\n",
    "\n",
    "    main(fname, dataset_name, ftype_output=ftype_output, output_data_stage=output_data_stage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
