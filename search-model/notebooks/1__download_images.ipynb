{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse-Image Search for Graphische Sammlung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image size options   \n",
    "150x150 default  \n",
    "250x250 resolution=mediumImageResolution  \n",
    "350x350 resolution=highImageResolution  \n",
    "max resolution=superImageResolution  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_url = \"https://www.e-gs.ethz.ch/eMP/eMuseumPlus?service=ImageAsset&module=collection&objectId=2562&resolution=mediumImageResolution\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Downloading\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import logging\n",
    "\n",
    "sys.path.append('../src')\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_folder(string):\n",
    "# divide into folders of 999 pictures max\n",
    "\n",
    "    if len(string)>3:\n",
    "\n",
    "        fldr = string[0:-3]\n",
    "    else:\n",
    "        fldr = \"0\"\n",
    "\n",
    "    return fldr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_img_url_resolution(url, new_resolution=\"highImageResolution\"):\n",
    "    \n",
    "    split_str = '&resolution='\n",
    "    new_resolution = \"highImageResolution\"\n",
    "    \n",
    "    return url.split(split_str)[0] + split_str + new_resolution\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dict_from_series(ser_a, ser_b):\n",
    "\n",
    "    # make dict of filename:url\n",
    "    ser_a_lst = ser_a.to_list()\n",
    "    ser_b_lst = ser_b.to_list()\n",
    "    ser_dict = dict(zip( ser_a_lst, ser_b_lst))\n",
    "\n",
    "    return ser_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sleep_range(sleep_time_range=(1,3)):\n",
    "    sleep_time = random.uniform(*sleep_time_range)\n",
    "    sleep(sleep_time)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(file_dict, sleep_time_range=(3,5)):\n",
    " \n",
    "    \"\"\"loops through a dictionary of files to download. includes logging\n",
    "    file_dict: should be in the format {file_fullpath:url }\n",
    "    \"\"\"\n",
    "     \n",
    "    total_num_images = len(file_dict)\n",
    "    msg = f\"started download of {total_num_images} images\"\n",
    "    print(msg)\n",
    "    logging.info(msg)\n",
    "\n",
    "    #loop to download from each url\n",
    "    for i, (filepath, url) in enumerate(file_dict.items()):\n",
    "\n",
    "        utils.log_status_at_interval(i, total_num_images, interval=100, _log=True, _print=False)\n",
    "\n",
    "        # download image\n",
    "        if not os.path.exists(filepath):\n",
    "            #make subfolders in file path if doesn't exist\n",
    "            utils.prep_dir(filepath)\n",
    "            utils.download_image(filepath, url)\n",
    "        else:\n",
    "            logging.warning('image already exists {}'.format(filepath))\n",
    "\n",
    "        random_sleep_range(sleep_time_range)\n",
    "        utils.print_dyn_progress_bar(total_num_images, i)\n",
    "\n",
    "    logging.info('finished download')\n",
    "    print('\\nfinished download')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_existing_files(df, fldr_path, fpath_col='filepath'):\n",
    "    \n",
    "    existing_flist = utils.list_files_in_dir(fldr_path)\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(fldr_path):\n",
    "        for fname in filenames:\n",
    "            cur_fpath = os.path.join(dirpath,fname)\n",
    "            existing_flist.append(cur_fpath)\n",
    "\n",
    "    orig_len = df.shape[0]\n",
    "\n",
    "    # filter out already existing\n",
    "    fltr = ~df[fpath_col].isin(existing_flist)\n",
    "    df = df.loc[fltr, :]\n",
    "\n",
    "    num_dropped = orig_len - df.shape[0]\n",
    "    print('removed {} records with images already saved'.format(num_dropped))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fpaths_col(ser_obj_ids, output_dir):\n",
    "    \n",
    "    ser_fpaths = ser_obj_ids.apply(set_folder)\n",
    "    ser_fpaths = output_dir + '/' + ser_fpaths + '/' + ser_obj_ids + \".png\"\n",
    "    \n",
    "    return ser_fpaths.apply(os.path.normpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_download_df(df, output_dir):\n",
    "    \n",
    "    df['object_id'] = df['object_id'].astype(int).astype(str)\n",
    "    \n",
    "    # make filepath column\n",
    "    df['filepath'] = make_fpaths_col(df['object_id'], output_dir)\n",
    "\n",
    "    # drop already downloaded records\n",
    "    df = filter_existing_files(df, output_dir)\n",
    "\n",
    "    # change image url to lower res\n",
    "    df.loc[:,'img_url'] = df['img_url'].apply(change_img_url_resolution)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN\n",
    "## download images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned csv with list of image_ids\n",
    "fname = 'image_search_ids.csv'\n",
    "fpath = os.path.join('..','data','interim','ethz', fname)\n",
    "output_dir = os.path.join('..','data','raw','ethz','images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 21107 records with images already saved\n"
     ]
    }
   ],
   "source": [
    "# def main(fpath, output_dir, )\n",
    "\n",
    "df = pd.read_csv(fpath, usecols=['object_id','img_url'])\n",
    "df = prep_download_df(df, output_dir)\n",
    "img_dict = make_dict_from_series(df['filepath'], df['img_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.init_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started download of 0 images\n",
      "\n",
      "finished download\n"
     ]
    }
   ],
   "source": [
    "save_images(img_dict, sleep_time_range=(1,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
